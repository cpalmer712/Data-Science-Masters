{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0fc485a6-390a-4cfd-89a9-04190698e108",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Defining the vector variable Y\n",
    "Y = np.array([1,0,1,4,3,2,5,6,9,13,15,16])\n",
    "\n",
    "# Defining the (3,12) matrix as X\n",
    "X = np.array([[1,1,1],\n",
    "          [1,2,1],\n",
    "          [1,2,2],\n",
    "          [1,3,2],\n",
    "          [1,5,4],\n",
    "          [1,5,6],\n",
    "          [1,6,5],\n",
    "          [1,7,4],\n",
    "          [1,10,8],\n",
    "          [1,11,7],\n",
    "          [1,11,9],\n",
    "          [1,12,10]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c6e24da5-3d00-4902-a8b4-dddbe77a7988",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the linear regression function and calculating the loss.\n",
    "def linear_regression(b, X, Y):\n",
    "    y_pred = X @ b\n",
    "    loss = np.sum((y_pred - Y)**2)\n",
    "    return loss\n",
    "\n",
    "#Defining the gradient descent function\n",
    "def gradient_descent(X, Y, learning_rate, num_iterations):\n",
    "    n = len(X)      # Number of rows\n",
    "    p = len(X[0])   # Number of columns\n",
    "    \n",
    "    #initializing the beta and best_beta to 0\n",
    "    b = np.zeros(p)\n",
    "    best_loss = float(\"inf\")\n",
    "    best_beta = np.zeros(p)\n",
    "    \n",
    "    #calculating the gradient of the loss function at beta\n",
    "    for i in num_iterations:\n",
    "        y_pred = X @ b\n",
    "        gradient = (2 * X.T) @ (y_pred - Y)\n",
    "        \n",
    "        #Update Beta\n",
    "        b = b - learning_rate * gradient\n",
    "        \n",
    "        #Keep track of best seen so far loss and parameters.\n",
    "        current_loss = linear_regression(b, X, Y)\n",
    "        \n",
    "        if (current_loss < best_loss):\n",
    "            best_loss = current_loss\n",
    "            best_beta = b\n",
    "        #print beta and loss update within the for loop. only print first 9 and last 9\n",
    "        #iterations\n",
    "        if (i<10 or i > 29990):\n",
    "            print(\"Iteration:\", i, \"Beta Values\", beta)\n",
    "            print(\"\\n\")\n",
    "            print(\"Best Loss: \", current_loss)\n",
    "            \n",
    "            \n",
    "    #return list of final results\n",
    "    return ({\"beta\": best_beta, \"loss\": best_loss})\n",
    "\n",
    "#set the learning rate and number of iterations. \n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "263cc97d-f4b8-4544-b45c-58208432393c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 Beta Values [-2.2630379   1.54972927 -0.2385295 ]\n",
      "\n",
      "\n",
      "Best Loss:  539.0223544\n",
      "Iteration: 1 Beta Values [-2.2630379   1.54972927 -0.2385295 ]\n",
      "\n",
      "\n",
      "Best Loss:  360.7318699583712\n",
      "Iteration: 2 Beta Values [-2.2630379   1.54972927 -0.2385295 ]\n",
      "\n",
      "\n",
      "Best Loss:  248.78911178512737\n",
      "Iteration: 3 Beta Values [-2.2630379   1.54972927 -0.2385295 ]\n",
      "\n",
      "\n",
      "Best Loss:  178.4977897913792\n",
      "Iteration: 4 Beta Values [-2.2630379   1.54972927 -0.2385295 ]\n",
      "\n",
      "\n",
      "Best Loss:  134.35420528676462\n",
      "Iteration: 5 Beta Values [-2.2630379   1.54972927 -0.2385295 ]\n",
      "\n",
      "\n",
      "Best Loss:  106.62553310358618\n",
      "Iteration: 6 Beta Values [-2.2630379   1.54972927 -0.2385295 ]\n",
      "\n",
      "\n",
      "Best Loss:  89.20175472042988\n",
      "Iteration: 7 Beta Values [-2.2630379   1.54972927 -0.2385295 ]\n",
      "\n",
      "\n",
      "Best Loss:  78.24715687403072\n",
      "Iteration: 8 Beta Values [-2.2630379   1.54972927 -0.2385295 ]\n",
      "\n",
      "\n",
      "Best Loss:  71.35377691342127\n",
      "Iteration: 9 Beta Values [-2.2630379   1.54972927 -0.2385295 ]\n",
      "\n",
      "\n",
      "Best Loss:  67.00995746756537\n",
      "Iteration: 29991 Beta Values [-2.2630379   1.54972927 -0.2385295 ]\n",
      "\n",
      "\n",
      "Best Loss:  34.10088344257623\n",
      "Iteration: 29992 Beta Values [-2.2630379   1.54972927 -0.2385295 ]\n",
      "\n",
      "\n",
      "Best Loss:  34.10088344257623\n",
      "Iteration: 29993 Beta Values [-2.2630379   1.54972927 -0.2385295 ]\n",
      "\n",
      "\n",
      "Best Loss:  34.10088344257624\n",
      "Iteration: 29994 Beta Values [-2.2630379   1.54972927 -0.2385295 ]\n",
      "\n",
      "\n",
      "Best Loss:  34.10088344257625\n",
      "Iteration: 29995 Beta Values [-2.2630379   1.54972927 -0.2385295 ]\n",
      "\n",
      "\n",
      "Best Loss:  34.10088344257624\n",
      "Iteration: 29996 Beta Values [-2.2630379   1.54972927 -0.2385295 ]\n",
      "\n",
      "\n",
      "Best Loss:  34.100883442576254\n",
      "Iteration: 29997 Beta Values [-2.2630379   1.54972927 -0.2385295 ]\n",
      "\n",
      "\n",
      "Best Loss:  34.10088344257623\n",
      "Iteration: 29998 Beta Values [-2.2630379   1.54972927 -0.2385295 ]\n",
      "\n",
      "\n",
      "Best Loss:  34.10088344257624\n",
      "Iteration: 29999 Beta Values [-2.2630379   1.54972927 -0.2385295 ]\n",
      "\n",
      "\n",
      "Best Loss:  34.10088344257623\n"
     ]
    }
   ],
   "source": [
    "#number of iterations 1-30000\n",
    "num_iterations = range(30000)\n",
    "\n",
    "#call and run the gradient descent function. \n",
    "result = gradient_descent(X, Y, learning_rate, num_iterations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "724cefef-6de1-4981-9f03-9fa0f32c08de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Betas and Loss:  {'beta': array([-2.26303788,  1.54972927, -0.2385295 ]), 'loss': 34.10088344257619}\n"
     ]
    }
   ],
   "source": [
    "#Prints the betas and loss\n",
    "print(\"Betas and Loss: \", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ea278960-4a6c-4af2-bb3c-d13ef7a2336f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.2630379   1.54972927 -0.2385295 ]\n"
     ]
    }
   ],
   "source": [
    "#Verify that betas are correct values using \"OLS Matrix Formulation\"\n",
    "beta = np.linalg.inv(X.T @ X) @ X.T @ Y\n",
    "print(beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba10905-c148-4a4e-aa9b-a6a594a81df7",
   "metadata": {},
   "source": [
    "The purpose of this code is to create a gradient descent algorithm from scratch. It begins by defining the vector(1x12) as Y, and the matrix(3x12) as X. First the loss function must be defined and calculated using \"np.sum((X @ b)- Y)^2\", using \"np.sum\" to compute the total sum of all rows and columns separately. Next the gradient descent function is designed requiring inputs for X, Y, learning_rate, and num_iterations which are defined in the function. Within the gradient descent function, the number of columns and rows are defined. Then the betas are initialized to 0 with the length \"p\" parameters used to store parameter values. Following this, a for loop is used to calculate the gradient descent and update the betas while keeping track of the best loss and parameters. If the current loss is less than the best loss, the beta and best loss is updated as the values decrease. Next, the number of returned values is defined as the first and last 10 values so that 30,000 values are not printed, but we get an idea if the gradient descent function is working etc. The best betas and best loss are then called outside of the gradient_descent function and the learning rate is defined at 0.0001 ensuring accurate results. The calculated betas are then verified using the OLS Matrix Formulation equation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c2f6eb-61b2-4b65-998b-a543ead9a577",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
